{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f805a4dd-a8e9-4721-9574-ea569df9a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tabula\n",
    "import math\n",
    "import os\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1f3f3724-49b9-4115-8c2f-27d0420a854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#este bloque busca los BOD en PDF en la carpeta de documentos (docs_dir), los compara con los documentos que ya se procesaron en su día guardados como .pkl (pkld_list) y genera una lista\n",
    "#de nombres de archivos a procesar (proc_docs)\n",
    "\n",
    "docs_dir = 'D:/jaume/Datasets/BOD2/'\n",
    "pkld_dir = 'D:/jaume/Jupyter Notebooks/Vacantes Scraper/ScrapedData2/'\n",
    "\n",
    "docs_list = []    #lista de documentos en la carpeta de entrada\n",
    "pkld_list = []    #lista de documentos ya procesados y transformados a pkl\n",
    "proc_docs = []    #lista de documentos aún por procesar\n",
    "\n",
    "# iterate over files in that directory\n",
    "for filename in os.scandir(docs_dir):\n",
    "    if filename.is_file():\n",
    "        docs_list.append(filename.name.split('_')[1])\n",
    "        \n",
    "# iterate over files in that directory\n",
    "for filename in os.scandir(pkld_dir):\n",
    "    if filename.is_file():\n",
    "        pkld_list.append(filename.name.split('.')[0])\n",
    "\n",
    "#seriales de documentos a procesar\n",
    "pending_list = [doc for doc in docs_list if doc not in pkld_list]\n",
    "\n",
    "# list of files to porcess\n",
    "for filename in os.scandir(docs_dir):\n",
    "    if filename.name.split('_')[1] in pending_list:\n",
    "        proc_docs.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "30be934c-aeeb-4bcb-8700-92168fb7a0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BOD_20220307_45.pdf...\n",
      "1 clean df,s in the list, ready to pack\n",
      "1 clean df,s in 2 lists, ready to pack\n",
      "20220307_45.pdf pickled!\n",
      "Processing BOD_20220309_47.pdf...\n",
      "4 clean df,s in the list, ready to pack\n",
      "4 clean df,s in 2 lists, ready to pack\n",
      "20220309_47.pdf pickled!\n"
     ]
    }
   ],
   "source": [
    "for doc in proc_docs:\n",
    "    \n",
    "    print('Processing ' + doc.name + '...')\n",
    "    file_pdf = docs_dir + doc.name\n",
    "    read_pdf = tabula.read_pdf(file_pdf, pages = 'all', silent = True)\n",
    "    \n",
    "    sel_tables = []                         #creará una lista (sel_tables) con los índices a mantener basado en el número de columnas de la tabla (14-16) y el número de filas (2)\n",
    "    oth_tables = []                         #creará una lista (sel_tables) con los índices a mantener basado en el número de columnas de la tabla (14-16) y el más de 2 filas (funcionan diferente)\n",
    "    for i in range(len(read_pdf)):\n",
    "        #seleccionamos sólo los df que contienen de 14 a 16 columnas y 2 filas\n",
    "        if np.logical_and(read_pdf[i].shape[0] == 2, np.logical_and(read_pdf[i].shape[1] >= 14, read_pdf[i].shape[1] <= 16)):\n",
    "            sel_tables.append(i)\n",
    "\n",
    "        \n",
    "        #seleccionamos sólo los df que contienen más de dos filas, no contienen \"voluntario o forzoso\" (esas son vacantes) y tienen de 14 a 16 columnas:\n",
    "        elif np.logical_and(\n",
    "            np.logical_and(~read_pdf[i].isin(['Servicio Activo']).any().any(),\n",
    "                           np.logical_and(read_pdf[i].shape[0] > 2, ~read_pdf[i].isin(['VOLUNTARIO', 'FORZOSO', 'VOL', 'FOR']).any().any())),\n",
    "            np.logical_and(read_pdf[i].shape[1] >= 14, read_pdf[i].shape[1] <= 16)):\n",
    "            oth_tables.append(i)    \n",
    "\n",
    "        #seleccionamos los destinos\n",
    "        elif read_pdf[i].isin(['VOLUNTARIO', 'FORZOSO', 'VOL', 'FOR']).any().any():\n",
    "            pass    #aquí FALTA incluir el código para crear una lista de DF de DESTINOS\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    df_list = [read_pdf[index] for index in sel_tables]    #conservará los elementos de read_tables seleccionados en sel_tables\n",
    "    oth_list = [read_pdf[index] for index in oth_tables]    #conservará los elementos de read_tables seleccionados en sel_tables\n",
    "\n",
    "    df_clean = []\n",
    "    oth_clean = []\n",
    "    errors = []\n",
    "\n",
    "    #código para los df de shape (2, 14-16) almacenados en df_list\n",
    "\n",
    "    for i in range(len(df_list)):\n",
    "        df = df_list[i]                                   #iteramos los df seleccionados en df_list\n",
    "        col_list =[]                                      #instanciamos la lista de columnas vacía que se poblará con los 'split' de cada columna del df de esta iteración\n",
    "        string = [np.nan] * df.shape[1]\n",
    "        col = [np.nan] * df.shape[1]\n",
    "        \n",
    "        if isinstance(df.iloc[1, 0], str):                    #n_vacs define el número de vacantes que se esperan (num de vacantes separadas por \\r en la 1a col del DF)\n",
    "            n_vacs = len(df.iloc[1, 0].split('\\r'))\n",
    "            \n",
    "        elif isinstance(df.iloc[1, 0], float):\n",
    "            n_vacs = 1\n",
    "            \n",
    "        else:\n",
    "            print('DF-' + str(i) + 'found a ' + str(type(df.iloc[1, 0])) + ' in iloc [0, 1]')\n",
    "\n",
    "        for j in range(df.shape[1]):                      #iteramos cada columna (str separado por '\\r') del df para convertirlo en una lista de valores de la columna\n",
    "\n",
    "            string[j] = df.iloc[1, j]\n",
    "\n",
    "            if type(string[j]) == str:\n",
    "\n",
    "                col[j] = string[j].split('\\r')            #columna resultante de la separación de 'string'\n",
    "\n",
    "                if len(col[j]) == n_vacs:\n",
    "                    col_list.append(col[j])               #si la columna tiene exactamente el mismo número de registros que el número de vacantes del df, adjuntamos la columna\n",
    "\n",
    "                elif math.ceil(len(col[j])/2) == n_vacs:\n",
    "                    col_list.append(col[j][0::2])         #si la columna tiene el doble (redondeado) de registros que el número de vacantes del df, adjuntamos la columna cada dos espacios\n",
    "\n",
    "                else:                                     #si no tiene el mismo número, lanzamos la lógica para colocar todos los valores posibles en ese registro y marcamos el error\n",
    "                    errors.append('DF-' + str(i) + ' Elementos no definidos en todas las vacantes. Ver opciones.')\n",
    "                    unique = set(col[j])\n",
    "                    values = list(unique)\n",
    "                    values.append(np.nan)\n",
    "                    col_list.append([values] * n_vacs)\n",
    "            \n",
    "            elif type(string[j]) == np.float64:\n",
    "                col[j] = string[j]\n",
    "                col_list.append(col[j])\n",
    "                \n",
    "            else:\n",
    "                col_list.append([np.nan] * n_vacs)\n",
    "\n",
    "        col_map = {}\n",
    "        if np.logical_and(len(col_list) == 14, np.logical_and('PA' not in col_list[5], 'LD' not in col_list[5])):                             #mapeo según resoluciones de 14 columnas\n",
    "            col_map = {'n_vac': col_list[0],\n",
    "                       'uco': col_list[1],\n",
    "                       'ciu': col_list[2],\n",
    "                       'pt': col_list[3],\n",
    "                       'asig': col_list[4],\n",
    "                       'ta': col_list[5],\n",
    "                       'empleo': col_list[6],\n",
    "                       'efun': col_list[7],\n",
    "                       'cursos': col_list[8],\n",
    "                       't_max': col_list[9],\n",
    "                       't_min': col_list[10],\n",
    "                       'fecha_cob': col_list[11],\n",
    "                       'csce': col_list[12],\n",
    "                       'obs': col_list[13]\n",
    "                      }\n",
    "            \n",
    "        elif np.logical_and(len(col_list) == 14, np.logical_or('PA' in col_list[5], 'LD' in col_list[5])):                             #mapeo según resoluciones de 14 columnas\n",
    "            col_map = {'n_vac': col_list[0],\n",
    "                       'uco': col_list[1],\n",
    "                       'ciu': col_list[2],\n",
    "                       'pt': col_list[3],\n",
    "                       'asig': col_list[5],\n",
    "                       'ta': col_list[6],\n",
    "                       'empleo': col_list[7],\n",
    "                       'efun': col_list[8],\n",
    "                       'cursos': col_list[10],\n",
    "                       'csce': col_list[12],\n",
    "                       'obs': col_list[13],\n",
    "                       'cantidad_vacantes': col_list[4]\n",
    "                      }\n",
    "\n",
    "        elif np.logical_and(len(col_list) == 15, 'CM' in col_list[4]):                           #mapeo según resoluciones de 15 columnas agregar condición 'y en la columna 4 contiene CM' para\n",
    "            col_map = {'n_vac': col_list[0],                                                     #deconflictar con vacantes de RESERVA\n",
    "                       'uco': col_list[1],\n",
    "                       'ciu': col_list[2],\n",
    "                       'pt': col_list[3],\n",
    "                       'asig': col_list[4],\n",
    "                       'ta': col_list[5],\n",
    "                       'empleo': col_list[6],\n",
    "                       'efun': col_list[7],\n",
    "                       'cursos': col_list[8],\n",
    "                       't_max': col_list[9],\n",
    "                       't_min': col_list[10],\n",
    "                       'fecha_cob': col_list[11],\n",
    "                       'csce': col_list[12],\n",
    "                       'cod_cm': col_list[13],\n",
    "                       'obs': col_list[14]\n",
    "                      }\n",
    "            \n",
    "        elif np.logical_and(len(col_list) == 15, 'CM' not in col_list[4]):                           #mapeo según resoluciones de 15 columnas diferentes a CM (pendiente mapeo)\n",
    "            col_map = {'n_vac': col_list[0],\n",
    "                       'uco': col_list[1],\n",
    "                       'ciu': col_list[2],\n",
    "                       'pt': col_list[3],\n",
    "                       'asig': col_list[4],\n",
    "                       'empleo': col_list[7],\n",
    "                       'csce': col_list[13],\n",
    "                       'obs': col_list[14]\n",
    "                      }\n",
    "\n",
    "        elif len(col_list) == 16:                           #mapeo según resoluciones de 16 columnas\n",
    "            col_map = {'n_vac': col_list[0],\n",
    "                       'uco': col_list[1],\n",
    "                       'ciu': col_list[2],\n",
    "                       'pt': col_list[3],\n",
    "                       'asig': col_list[4],\n",
    "                       'ta': col_list[5],\n",
    "                       'ejercito': col_list[6],\n",
    "                       'cuerpo_esc': col_list[7],\n",
    "                       'empleo': col_list[8],\n",
    "                       'efun': col_list[9],\n",
    "                       'cursos': col_list[10],\n",
    "                       't_max': col_list[11],\n",
    "                       't_min': col_list[12],\n",
    "                       'nivel': col_list[13],   #comprobar que esto es así siempre.\n",
    "                       'csce': col_list[14],\n",
    "                       'obs': col_list[15]\n",
    "                      }\n",
    "\n",
    "        else:\n",
    "            errors.append('DF-' + str(i) + ' has wrong COL MAPPING')\n",
    "\n",
    "\n",
    "        try:\n",
    "            if ~pd.DataFrame(col_map).isin(['VOLUNTARIO', 'FORZOSO']).any().any():    #comprobamos que no son DESTINOS. esta característica los distingue.\n",
    "                data = pd.DataFrame(col_map)\n",
    "                data['fecha_pub'] = pkl_name_parts[1]\n",
    "                df_clean.append(data)\n",
    "            else: pass\n",
    "\n",
    "        except:\n",
    "            errors.append('DF-' + str(i) + ' threw an error in DataFrame')\n",
    "\n",
    "\n",
    "\n",
    "    print(str(len(df_clean)) + ' clean df,s in the list, ready to pack')\n",
    "\n",
    "    #código para los df de shape (2+, 14-16) almacenados en oth_list\n",
    "\n",
    "    for oth_df in oth_list:\n",
    "\n",
    "        oth_df = oth_df.iloc[1::2]\n",
    "\n",
    "        vac_uco = oth_df.iloc[:, 0].str.split(n = 1, expand = True)\n",
    "        \n",
    "        if vac_uco.shape[1] == 2:                                     #si la línea para crear vac_uco genera dos columnas (n_vac y UCO) el código es bueno y sigue.\n",
    "            n_vac = vac_uco.iloc[:, 0]\n",
    "            uco = vac_uco.iloc[:, 1]    \n",
    "        \n",
    "        else:                                                         #si no crea dos columnas es un error, el DF no me sirve, saltamos al siguiente.\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        clas_ta = oth_df['CLAS.'].str.split(n = 1, expand = True)    \n",
    "        asig = clas_ta.iloc[:, 0]\n",
    "        ta = clas_ta.iloc[:, 1]\n",
    "        \n",
    "        obs = oth_df.iloc[:, -1]\n",
    "\n",
    "        assert len(n_vac) == len(uco) == len(asig) == len(ta)        #checkea que hay tantos n_vac como ucos, modos de asignación y TAs\n",
    "        \n",
    "        pt_ind = 0\n",
    "        ciu_ind = 0\n",
    "        cm_ind = 0\n",
    "        csce_ind = 0\n",
    "        empleo_ind = 0\n",
    "\n",
    "        for i in range(oth_df.shape[1]):\n",
    "\n",
    "                if all([isinstance(e, str) for e in oth_df.iloc[:, i]]):\n",
    "                    if round(oth_df.iloc[:, i].str.len().mean()) == 8:\n",
    "                        ciu_ind = i\n",
    "  \n",
    "                    elif oth_df.iloc[:, i].str.count('/').sum() == len(oth_df.iloc[:, i]):\n",
    "                        pt_ind = i\n",
    "   \n",
    "                    elif np.logical_and(oth_df.iloc[:, i].str.len().mean() == 4, ~oth_df.iloc[:, i].str.contains('SDO|CBO|CBO 1º|CBMY|SGTO|SGTO 1º|BG|STTE|SBMY|ALF|TTE|CAP|CTE|TCOL|COL').all()):\n",
    "                        cm_ind = i\n",
    "          \n",
    "                    elif oth_df.iloc[:, i].str.len().mean() == 6:\n",
    "                        csce_ind = i\n",
    "            \n",
    "                    elif oth_df.iloc[:, i].str.contains('SDO|CBO|CBO 1º|CBMY|SGTO|SGTO 1º|BG|STTE|SBMY|ALF|TTE|CAP|CTE|TCOL|COL').sum() == len(oth_df.iloc[:, i]):\n",
    "                        empleo_ind = i\n",
    "                        \n",
    "                    else: pass\n",
    "        \n",
    "\n",
    "        col_map = {'n_vac': n_vac,\n",
    "               'uco': uco,\n",
    "               'ciu': oth_df.iloc[:, ciu_ind],\n",
    "               'pt': oth_df.iloc[:, pt_ind],\n",
    "               'asig': asig,\n",
    "               'ta': ta,\n",
    "               'empleo': oth_df.iloc[:, empleo_ind],\n",
    "    #           'efun': col_list[7],\n",
    "    #           'cursos': col_list[8],\n",
    "    #           't_max': col_list[9],\n",
    "    #           't_min': col_list[10],\n",
    "    #           'fecha_cob': col_list[11],\n",
    "               'csce': oth_df.iloc[:, csce_ind],\n",
    "               'cod_cm': oth_df.iloc[:, cm_ind],\n",
    "               'obs': obs\n",
    "              }\n",
    "\n",
    "\n",
    "        data = pd.DataFrame(col_map)\n",
    "        data['fecha_pub'] = pkl_name_parts[1]\n",
    "        oth_clean.append(data)\n",
    "\n",
    "\n",
    "        errors.append('DF_OTH-' + str(i) + ' threw an error in DataFrame')\n",
    "\n",
    "    print(str(len(df_clean)+len(oth_clean)) + ' clean df,s in 2 lists, ready to pack')\n",
    "\n",
    "    try:\n",
    "        df_full = pd.concat(df_clean + oth_clean).reset_index(drop = True)      #la solución!!!\n",
    "    except: pass\n",
    "    \n",
    "    pkl_name_parts = file_pdf.split('_')\n",
    "    pkl_name = pkl_name_parts[1] + '.pkl'\n",
    "\n",
    "    df_full.to_pickle(pkld_dir + pkl_name)\n",
    "\n",
    "    print(str(pkl_name_parts[1]) + '_' + str(pkl_name_parts[2]) + ' pickled!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01902538-8a78-47bc-b58b-a1d6b09cdd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DF-0 Elementos no definidos en todas las vacantes. Ver opciones.',\n",
       " 'DF-0 Elementos no definidos en todas las vacantes. Ver opciones.',\n",
       " 'DF-0 Elementos no definidos en todas las vacantes. Ver opciones.',\n",
       " 'DF-1 Elementos no definidos en todas las vacantes. Ver opciones.',\n",
       " 'DF-1 Elementos no definidos en todas las vacantes. Ver opciones.',\n",
       " 'DF-2 Elementos no definidos en todas las vacantes. Ver opciones.',\n",
       " 'DF-2 Elementos no definidos en todas las vacantes. Ver opciones.',\n",
       " 'DF-2 Elementos no definidos en todas las vacantes. Ver opciones.',\n",
       " 'DF-2 Elementos no definidos en todas las vacantes. Ver opciones.',\n",
       " 'DF-3 Elementos no definidos en todas las vacantes. Ver opciones.',\n",
       " 'DF-3 Elementos no definidos en todas las vacantes. Ver opciones.',\n",
       " 'DF-3 Elementos no definidos en todas las vacantes. Ver opciones.']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336409f3-3f91-4f2b-a6bf-d3a7e544068f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
