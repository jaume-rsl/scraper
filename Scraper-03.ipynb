{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f805a4dd-a8e9-4721-9574-ea569df9a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tabula\n",
    "import math\n",
    "import os\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f3f3724-49b9-4115-8c2f-27d0420a854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#este bloque busca los BOD en PDF en la carpeta de documentos (docs_dir), los compara con los documentos que ya se procesaron en su día guardados como .pkl (pkld_list) y genera una lista\n",
    "#de nombres de archivos a procesar (proc_docs)\n",
    "\n",
    "docs_dir = 'D:/jaume/Datasets/BOD/'\n",
    "pkld_dir = 'D:/jaume/Jupyter Notebooks/Vacantes Scraper/ScrapedData/'\n",
    "\n",
    "docs_list = []    #lista de documentos en la carpeta de entrada\n",
    "pkld_list = []    #lista de documentos ya procesados y transformados a pkl\n",
    "proc_docs = []    #lista de documentos aún por procesar\n",
    "\n",
    "# iterate over files in that directory\n",
    "for filename in os.scandir(docs_dir):\n",
    "    if filename.is_file():\n",
    "        docs_list.append(filename.name.split('_')[1])\n",
    "        \n",
    "# iterate over files in that directory\n",
    "for filename in os.scandir(pkld_dir):\n",
    "    if filename.is_file():\n",
    "        pkld_list.append(filename.name.split('.')[0])\n",
    "\n",
    "#seriales de documentos a procesar\n",
    "pending_list = [doc for doc in docs_list if doc not in pkld_list]\n",
    "\n",
    "# list of files to porcess\n",
    "for filename in os.scandir(docs_dir):\n",
    "    if filename.name.split('_')[1] in pending_list:\n",
    "        proc_docs.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30be934c-aeeb-4bcb-8700-92168fb7a0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BOD_20220125_16.pdf...\n",
      "2 clean df,s in the list, ready to pack\n",
      "3 clean df,s in 2 lists, ready to pack\n",
      "20220125_16.pdf pickled!\n"
     ]
    }
   ],
   "source": [
    "for doc in proc_docs:\n",
    "    \n",
    "    print('Processing ' + doc.name + '...')\n",
    "    file_pdf = docs_dir + doc.name\n",
    "    read_pdf = tabula.read_pdf(file_pdf, pages = 'all', silent = True)\n",
    "    \n",
    "    sel_tables = []                         #creará una lista (sel_tables) con los índices a mantener basado en el número de columnas de la tabla (14-16) y el número de filas (2)\n",
    "    oth_tables = []                         #creará una lista (sel_tables) con los índices a mantener basado en el número de columnas de la tabla (14-16) y el más de 2 filas (funcionan diferente)\n",
    "    for i in range(len(read_pdf)):\n",
    "        #seleccionamos sólo los df que contienen de 14 a 16 columnas y 2 filas\n",
    "        if np.logical_and(read_pdf[i].shape[0] == 2, np.logical_and(read_pdf[i].shape[1] >= 14, read_pdf[i].shape[1] <= 16)):\n",
    "            sel_tables.append(i)\n",
    "\n",
    "        \n",
    "        #seleccionamos sólo los df que contienen más de dos filas, no contienen \"voluntario o forzoso\" (esas son vacantes) y tienen de 14 a 16 columnas:\n",
    "        elif np.logical_and(\n",
    "            np.logical_and(~read_pdf[i].isin(['Servicio Activo']).any().any(),\n",
    "                           np.logical_and(read_pdf[i].shape[0] > 2, ~read_pdf[i].isin(['VOLUNTARIO', 'FORZOSO', 'VOL', 'FOR']).any().any())),\n",
    "            np.logical_and(read_pdf[i].shape[1] >= 14, read_pdf[i].shape[1] <= 16)):\n",
    "            oth_tables.append(i)    \n",
    "\n",
    "        #seleccionamos los destinos\n",
    "        elif read_pdf[i].isin(['VOLUNTARIO', 'FORZOSO', 'VOL', 'FOR']).any().any():\n",
    "            pass    #aquí FALTA incluir el código para crear una lista de DF de DESTINOS\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    df_list = [read_pdf[index] for index in sel_tables]    #conservará los elementos de read_tables seleccionados en sel_tables\n",
    "    oth_list = [read_pdf[index] for index in oth_tables]    #conservará los elementos de read_tables seleccionados en sel_tables\n",
    "\n",
    "    df_clean = []\n",
    "    oth_clean = []\n",
    "    errors = []\n",
    "\n",
    "    #código para los df de shape (2, 14-16) almacenados en df_list\n",
    "\n",
    "    for i in range(len(df_list)):\n",
    "        df = df_list[i]                                   #iteramos los df seleccionados en df_list\n",
    "        col_list =[]                                      #instanciamos la lista de columnas vacía que se poblará con los 'split' de cada columna del df de esta iteración\n",
    "        string = [np.nan] * df.shape[1]\n",
    "        col = [np.nan] * df.shape[1]\n",
    "        \n",
    "        if isinstance(df.iloc[1, 0], str):                    #n_vacs define el número de vacantes que se esperan (num de vacantes separadas por \\r en la 1a col del DF)\n",
    "            n_vacs = len(df.iloc[1, 0].split('\\r'))\n",
    "            \n",
    "        elif isinstance(df.iloc[1, 0], float):\n",
    "            n_vacs = 1\n",
    "            \n",
    "        else:\n",
    "            print('DF-' + str(i) + 'found a ' + str(type(df.iloc[1, 0])) + ' in iloc [0, 1]')\n",
    "\n",
    "        for j in range(df.shape[1]):                      #iteramos cada columna (str separado por '\\r') del df para convertirlo en una lista de valores de la columna\n",
    "\n",
    "            string[j] = df.iloc[1, j]\n",
    "\n",
    "            if type(string[j]) == str:\n",
    "\n",
    "                col[j] = string[j].split('\\r')            #columna resultante de la separación de 'string'\n",
    "\n",
    "                if len(col[j]) == n_vacs:\n",
    "                    col_list.append(col[j])               #si la columna tiene exactamente el mismo número de registros que el número de vacantes del df, adjuntamos la columna\n",
    "\n",
    "                elif math.ceil(len(col[j])/2) == n_vacs:\n",
    "                    col_list.append(col[j][0::2])         #si la columna tiene el doble (redondeado) de registros que el número de vacantes del df, adjuntamos la columna cada dos espacios\n",
    "\n",
    "                else:                                     #si no tiene el mismo número, lanzamos la lógica para colocar todos los valores posibles en ese registro y marcamos el error\n",
    "                    errors.append('DF-' + str(i) + ' Elementos de la columna ' + str(j) + ' no definidos en todas las vacantes. Ver opciones.')\n",
    "                    unique = set(col[j])\n",
    "                    values = list(unique)\n",
    "                    values.append(np.nan)\n",
    "                    col_list.append([values] * n_vacs)\n",
    "            \n",
    "            elif type(string[j]) == np.float64:\n",
    "                col[j] = string[j]\n",
    "                col_list.append(col[j])\n",
    "                \n",
    "            else:\n",
    "                col_list.append([np.nan] * n_vacs)\n",
    "\n",
    "        col_map = {}\n",
    "        if np.logical_and(len(col_list) == 14, np.logical_and('PA' not in col_list[5], 'LD' not in col_list[5])):                             #mapeo según resoluciones de 14 columnas\n",
    "            col_map = {'n_vac': col_list[0],\n",
    "                       'uco': col_list[1],\n",
    "                       'ciu': col_list[2],\n",
    "                       'pt': col_list[3],\n",
    "                       'asig': col_list[4],\n",
    "                       'ta': col_list[5],\n",
    "                       'empleo': col_list[6],\n",
    "                       'efun': col_list[7],\n",
    "                       'cursos': col_list[8],\n",
    "                       't_max': col_list[9],\n",
    "                       't_min': col_list[10],\n",
    "                       'fecha_cob': col_list[11],\n",
    "                       'csce': col_list[12],\n",
    "                       'obs': col_list[13]\n",
    "                      }\n",
    "            \n",
    "        elif np.logical_and(len(col_list) == 14, np.logical_or('PA' in col_list[5], 'LD' in col_list[5])):                             #mapeo según resoluciones de 14 columnas\n",
    "            col_map = {'n_vac': col_list[0],\n",
    "                       'uco': col_list[1],\n",
    "                       'ciu': col_list[2],\n",
    "                       'pt': col_list[3],\n",
    "                       'asig': col_list[5],\n",
    "                       'ta': col_list[6],\n",
    "                       'empleo': col_list[7],\n",
    "                       'efun': col_list[8],\n",
    "                       'cursos': col_list[10],\n",
    "                       'csce': col_list[12],\n",
    "                       'obs': col_list[13],\n",
    "                       'cantidad_vacantes': col_list[4]\n",
    "                      }\n",
    "\n",
    "        elif np.logical_and(len(col_list) == 15, 'CM' in col_list[4]):                           #mapeo según resoluciones de 15 columnas agregar condición 'y en la columna 4 contiene CM' para\n",
    "            col_map = {'n_vac': col_list[0],                                                     #deconflictar con vacantes de RESERVA\n",
    "                       'uco': col_list[1],\n",
    "                       'ciu': col_list[2],\n",
    "                       'pt': col_list[3],\n",
    "                       'asig': col_list[4],\n",
    "                       'ta': col_list[5],\n",
    "                       'empleo': col_list[6],\n",
    "                       'efun': col_list[7],\n",
    "                       'cursos': col_list[8],\n",
    "                       't_max': col_list[9],\n",
    "                       't_min': col_list[10],\n",
    "                       'fecha_cob': col_list[11],\n",
    "                       'csce': col_list[12],\n",
    "                       'cod_cm': col_list[13],\n",
    "                       'obs': col_list[14]\n",
    "                      }\n",
    "            \n",
    "        elif np.logical_and(len(col_list) == 15, 'CM' not in col_list[4]):                           #mapeo según resoluciones de 15 columnas diferentes a CM (pendiente mapeo)\n",
    "            col_map = {'n_vac': col_list[0],\n",
    "                       'uco': col_list[1],\n",
    "                       'ciu': col_list[2],\n",
    "                       'pt': col_list[3],\n",
    "                       'asig': col_list[4],\n",
    "                       'empleo': col_list[7],\n",
    "                       'csce': col_list[13],\n",
    "                       'obs': col_list[14]\n",
    "                      }\n",
    "\n",
    "        elif len(col_list) == 16:                           #mapeo según resoluciones de 16 columnas\n",
    "            col_map = {'n_vac': col_list[0],\n",
    "                       'uco': col_list[1],\n",
    "                       'ciu': col_list[2],\n",
    "                       'pt': col_list[3],\n",
    "                       'asig': col_list[4],\n",
    "                       'ta': col_list[5],\n",
    "                       'ejercito': col_list[6],\n",
    "                       'cuerpo_esc': col_list[7],\n",
    "                       'empleo': col_list[8],\n",
    "                       'efun': col_list[9],\n",
    "                       'cursos': col_list[10],\n",
    "                       't_max': col_list[11],\n",
    "                       't_min': col_list[12],\n",
    "                       'nivel': col_list[13],   #comprobar que esto es así siempre.\n",
    "                       'csce': col_list[14],\n",
    "                       'obs': col_list[15]\n",
    "                      }\n",
    "\n",
    "        else:\n",
    "            errors.append('DF-' + str(i) + ' has wrong COL MAPPING')\n",
    "\n",
    "\n",
    "        try:\n",
    "            if ~pd.DataFrame(col_map).isin(['VOLUNTARIO', 'FORZOSO']).any().any():    #comprobamos que no son DESTINOS. esta característica los distingue.\n",
    "                data = pd.DataFrame(col_map)\n",
    "                df_clean.append(data)\n",
    "            else: pass\n",
    "\n",
    "        except:\n",
    "            errors.append('DF-' + str(i) + ' threw an error in DataFrame')\n",
    "\n",
    "\n",
    "\n",
    "    print(str(len(df_clean)) + ' clean df,s in the list, ready to pack')\n",
    "\n",
    "    #código para los df de shape (2+, 14-16) almacenados en oth_list\n",
    "\n",
    "    for oth_df in oth_list:\n",
    "\n",
    "        oth_df = oth_df.iloc[1::2]\n",
    "\n",
    "        vac_uco = oth_df.iloc[:, 0].str.split(n = 1, expand = True)\n",
    "        \n",
    "        if vac_uco.shape[1] == 2:                                     #si la línea para crear vac_uco genera dos columnas (n_vac y UCO) el código es bueno y sigue.\n",
    "            n_vac = vac_uco.iloc[:, 0]\n",
    "            uco = vac_uco.iloc[:, 1]    \n",
    "        \n",
    "        else:                                                         #si no crea dos columnas es un error, el DF no me sirve, saltamos al siguiente.\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        clas_ta = oth_df['CLAS.'].str.split(n = 1, expand = True)    \n",
    "        asig = clas_ta.iloc[:, 0]\n",
    "        ta = clas_ta.iloc[:, 1]\n",
    "        \n",
    "        obs = oth_df.iloc[:, -1]\n",
    "\n",
    "        assert len(n_vac) == len(uco) == len(asig) == len(ta)        #checkea que hay tantos n_vac como ucos, modos de asignación y TAs\n",
    "        \n",
    "        pt_ind = 0\n",
    "        ciu_ind = 0\n",
    "        cm_ind = 0\n",
    "        csce_ind = 0\n",
    "        empleo_ind = 0\n",
    "\n",
    "        for i in range(oth_df.shape[1]):\n",
    "\n",
    "                if all([isinstance(e, str) for e in oth_df.iloc[:, i]]):\n",
    "                    if round(oth_df.iloc[:, i].str.len().mean()) == 8:\n",
    "                        ciu_ind = i\n",
    "  \n",
    "                    elif oth_df.iloc[:, i].str.count('/').sum() == len(oth_df.iloc[:, i]):\n",
    "                        pt_ind = i\n",
    "   \n",
    "                    elif np.logical_and(oth_df.iloc[:, i].str.len().mean() == 4, ~oth_df.iloc[:, i].str.contains('SDO|CBO|CBO 1º|CBMY|SGTO|SGTO 1º|BG|STTE|SBMY|ALF|TTE|CAP|CTE|TCOL|COL').all()):\n",
    "                        cm_ind = i\n",
    "          \n",
    "                    elif oth_df.iloc[:, i].str.len().mean() == 6:\n",
    "                        csce_ind = i\n",
    "            \n",
    "                    elif oth_df.iloc[:, i].str.contains('SDO|CBO|CBO 1º|CBMY|SGTO|SGTO 1º|BG|STTE|SBMY|ALF|TTE|CAP|CTE|TCOL|COL').sum() == len(oth_df.iloc[:, i]):\n",
    "                        empleo_ind = i\n",
    "                        \n",
    "                    else: pass\n",
    "        \n",
    "\n",
    "        col_map = {'n_vac': n_vac,\n",
    "               'uco': uco,\n",
    "               'ciu': oth_df.iloc[:, ciu_ind],\n",
    "               'pt': oth_df.iloc[:, pt_ind],\n",
    "               'asig': asig,\n",
    "               'ta': ta,\n",
    "               'empleo': oth_df.iloc[:, empleo_ind],\n",
    "    #           'efun': col_list[7],\n",
    "    #           'cursos': col_list[8],\n",
    "    #           't_max': col_list[9],\n",
    "    #           't_min': col_list[10],\n",
    "    #           'fecha_cob': col_list[11],\n",
    "               'csce': oth_df.iloc[:, csce_ind],\n",
    "               'cod_cm': oth_df.iloc[:, cm_ind],\n",
    "               'obs': obs\n",
    "              }\n",
    "\n",
    "\n",
    "        data = pd.DataFrame(col_map)\n",
    "        oth_clean.append(data)\n",
    "        errors.append('DF_OTH-' + str(i) + ' threw an error in DataFrame')\n",
    "\n",
    "    print(str(len(df_clean)+len(oth_clean)) + ' clean df,s in 2 lists, ready to pack')\n",
    "\n",
    "    pkl_name_parts = file_pdf.split('_')\n",
    "\n",
    "    try:\n",
    "        df_full = pd.concat(df_clean + oth_clean).reset_index(drop = True)      #la solución!!!\n",
    "        df_full['fecha_pub'] = pkl_name_parts[1]\n",
    "    except: pass\n",
    "    \n",
    "    pkl_name = pkl_name_parts[1] + '.pkl'\n",
    "\n",
    "    df_full.to_pickle(pkld_dir + pkl_name)\n",
    "\n",
    "    print(str(pkl_name_parts[1]) + '_' + str(pkl_name_parts[2]) + ' pickled!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01902538-8a78-47bc-b58b-a1d6b09cdd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DF-0 Elementos de la columna 7 no definidos en todas las vacantes. Ver opciones.',\n",
       " 'DF-1 Elementos de la columna 3 no definidos en todas las vacantes. Ver opciones.',\n",
       " 'DF-1 Elementos de la columna 7 no definidos en todas las vacantes. Ver opciones.',\n",
       " 'DF_OTH-14 threw an error in DataFrame']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "336409f3-3f91-4f2b-a6bf-d3a7e544068f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUM.\\rVAC.</th>\n",
       "      <th>DIRECCION GENERAL, ORGANISMO, CENTRO, UNIDAD,\\rLOCALIDAD</th>\n",
       "      <th>CODIGO\\rIDENTIF.\\rUNIDAD</th>\n",
       "      <th>CODIGO\\rPUESTO\\rTRABAJO</th>\n",
       "      <th>CLAS.</th>\n",
       "      <th>EMPLEO</th>\n",
       "      <th>ESPEC. FUNDAMENTAL\\rESPEC. COMPLEMENTARIA</th>\n",
       "      <th>TITUL./SEG. ESP. EXIGIBLES\\rTITUL./SEG. ESP. VALORABLES</th>\n",
       "      <th>TIEMPOS</th>\n",
       "      <th>FECHA\\rCOBERTURA</th>\n",
       "      <th>CSCE\\rEUROS/MES</th>\n",
       "      <th>TIPO\\rCM</th>\n",
       "      <th>OBSERVACIONES</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS.</td>\n",
       "      <td>TA</td>\n",
       "      <td>MAX.</td>\n",
       "      <td>MIN.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00200\\r00201\\r00202\\r00203\\r00204\\r00205\\r0020...</td>\n",
       "      <td>AGRUPACION DE TRANSPORTE NUM.1\\rMADRID\\rCUARTE...</td>\n",
       "      <td>50022962\\r50030001\\r50001986\\r57005389\\r572948...</td>\n",
       "      <td>5JA39/002\\r5JA39/012\\r5JA39/006\\r5JA39/004\\r5J...</td>\n",
       "      <td>CM\\rCM\\rCM\\rCM\\rCM\\rCM\\rCM\\rCM\\rCM\\rCM</td>\n",
       "      <td>C\\rC\\rC\\rC\\rC\\rC\\rC\\rC\\rC\\rC</td>\n",
       "      <td>CTE\\rCTE\\rCTE\\rCTE\\rCTE\\rCTE\\rCTE\\rCTE\\rCTE\\rCTE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SL:I, RV:I, QM:I, GL:I\\rSL:I, RV:I, QM:I, GL:I...</td>\n",
       "      <td>10\\r10\\r10\\r10\\r10\\r10\\r10\\r10\\r10\\r10</td>\n",
       "      <td>3\\r3\\r3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499,78\\r499,78\\r499,78\\r499,78\\r382,37\\r499,78...</td>\n",
       "      <td>CM17\\rCM17\\rCM17\\rCM21\\rCM17\\rCM21\\rCM25\\rCM25...</td>\n",
       "      <td>244,511,959\\r244,511,656,960\\r244,511,656,960\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00210</td>\n",
       "      <td>BETERA (VALENCIA)\\rCUARTEL GENERAL DEL MANDO D...</td>\n",
       "      <td>50085418</td>\n",
       "      <td>5JA48/002</td>\n",
       "      <td>CM</td>\n",
       "      <td>C</td>\n",
       "      <td>CTE</td>\n",
       "      <td>TRA.</td>\n",
       "      <td>TI:E</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>540,28</td>\n",
       "      <td>CM15</td>\n",
       "      <td>244,511,656,960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          NUM.\\rVAC.  \\\n",
       "0                                                NaN   \n",
       "1  00200\\r00201\\r00202\\r00203\\r00204\\r00205\\r0020...   \n",
       "2                                              00210   \n",
       "\n",
       "  DIRECCION GENERAL, ORGANISMO, CENTRO, UNIDAD,\\rLOCALIDAD  \\\n",
       "0                                                NaN         \n",
       "1  AGRUPACION DE TRANSPORTE NUM.1\\rMADRID\\rCUARTE...         \n",
       "2  BETERA (VALENCIA)\\rCUARTEL GENERAL DEL MANDO D...         \n",
       "\n",
       "                            CODIGO\\rIDENTIF.\\rUNIDAD  \\\n",
       "0                                                NaN   \n",
       "1  50022962\\r50030001\\r50001986\\r57005389\\r572948...   \n",
       "2                                           50085418   \n",
       "\n",
       "                             CODIGO\\rPUESTO\\rTRABAJO  \\\n",
       "0                                                AS.   \n",
       "1  5JA39/002\\r5JA39/012\\r5JA39/006\\r5JA39/004\\r5J...   \n",
       "2                                          5JA48/002   \n",
       "\n",
       "                                    CLAS.                        EMPLEO  \\\n",
       "0                                      TA                          MAX.   \n",
       "1  CM\\rCM\\rCM\\rCM\\rCM\\rCM\\rCM\\rCM\\rCM\\rCM  C\\rC\\rC\\rC\\rC\\rC\\rC\\rC\\rC\\rC   \n",
       "2                                      CM                             C   \n",
       "\n",
       "          ESPEC. FUNDAMENTAL\\rESPEC. COMPLEMENTARIA  \\\n",
       "0                                              MIN.   \n",
       "1  CTE\\rCTE\\rCTE\\rCTE\\rCTE\\rCTE\\rCTE\\rCTE\\rCTE\\rCTE   \n",
       "2                                               CTE   \n",
       "\n",
       "  TITUL./SEG. ESP. EXIGIBLES\\rTITUL./SEG. ESP. VALORABLES  \\\n",
       "0                                                NaN        \n",
       "1                                                NaN        \n",
       "2                                               TRA.        \n",
       "\n",
       "                                             TIEMPOS  \\\n",
       "0                                                NaN   \n",
       "1  SL:I, RV:I, QM:I, GL:I\\rSL:I, RV:I, QM:I, GL:I...   \n",
       "2                                               TI:E   \n",
       "\n",
       "                         FECHA\\rCOBERTURA CSCE\\rEUROS/MES  TIPO\\rCM  \\\n",
       "0                                     NaN             NaN       NaN   \n",
       "1  10\\r10\\r10\\r10\\r10\\r10\\r10\\r10\\r10\\r10         3\\r3\\r3       NaN   \n",
       "2                                      10             NaN       NaN   \n",
       "\n",
       "                                       OBSERVACIONES  \\\n",
       "0                                                NaN   \n",
       "1  499,78\\r499,78\\r499,78\\r499,78\\r382,37\\r499,78...   \n",
       "2                                             540,28   \n",
       "\n",
       "                                          Unnamed: 0  \\\n",
       "0                                                NaN   \n",
       "1  CM17\\rCM17\\rCM17\\rCM21\\rCM17\\rCM21\\rCM25\\rCM25...   \n",
       "2                                               CM15   \n",
       "\n",
       "                                          Unnamed: 1  \n",
       "0                                                NaN  \n",
       "1  244,511,959\\r244,511,656,960\\r244,511,656,960\\...  \n",
       "2                                    244,511,656,960  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oth_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d64fa71-b69f-4e6e-b7d5-64e338719bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_csv('tst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97aefc1-d9c4-460f-9c7d-9eabccfad2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
